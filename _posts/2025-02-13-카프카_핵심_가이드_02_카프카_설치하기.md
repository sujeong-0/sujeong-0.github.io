---
title: 카프카 핵심 가이드 - 02 카프카 설치하기
description: >-
  카프카에 대해 정확하게 알기 위해 <kbd>카프카 핵심 가이드(그웬 샤피라, 토드 팔리노, 라지니 시바람, 크리트 페티 지음 / 이동진 옮김)</kbd>을 읽으며 공부한 내용을 정리
author: ggong
date: 2025-02-13 08:45:00 +0800
categories: [ Book, Kafka ]
tags: [ book, kafka, study, unclear ]
pin: true
media_subpath: '/assets/img/kafka'
---

## 환경 설정

### 운영체제 선택하기

아파치 카프카는 다양안 운영체제에서 실행가능한 자바 애플리케이션으로, 다양한 운영체제에서 실행이 가능하지만 대체로 리눅스가 권장된다.

### 자바 설치하기

카프카와 주키퍼는 모든 OpenJDK 기반 자바 구현체 위에서 원활히 작동된다.
카프카 최신 버전은 java 8과 11을 모두 지원한다.

### 주피커 설치하기

카프카는 카프카 클러스터의 메타데이터와 컨슈머 클라이언트에 대한 정보를 저장하기 위해 주피커를 사용한다.

![Build source](2-1.png){: .light .normal w='500'}

**주키퍼**
: 설정 정보 관리, 이름 부여, 분산 동기화, 그룹 서비스를 지공하는 중앙화된 서비스

## 카프카 브로커 설치하기

> 이 부분은 실제 설치 관련 글을 따로 작성 하려고 제외함
{: .prompt-warning }

## 브로커 설정하기

카프카에는 거의 모든 구성을 제어하고 튜닝할 수 있는 옵션 설정이 있는데, 대부분 특별한 사례가 아니라면 바꿀 일이 없다.

### 핵심 브로커 매개변수

브로커의 기본적인 설정을 담당하며, 대부분은 다른 브로커와 함께 클러스터 모드로 작동하기 위해서는 값을 변경해야한다.

**`broker.id`**
: 모든 카프카 브로커는 정숫값의 식별자를 갖는다.
: 클러스터 내의 모든 브로커들은 `broker.id`를 다르게 가져야한다.
: 임의로 설정이 가능하다.<question>필요하다면, 브로커 간에 이동도 가능하다.</question>

> **필요하다면, 브로커 간에 이동도 가능하다?**
: 브로커를 교체하거나 클러스터를 재구성할 때, 기존 브로커의 `broker.id`를 새로운 브로커에게 할당 가능하다.
{: .prompt-question .ms-4 }

**`listener`**
: 리스너는 `{프로토콜}://{호스트이름}:{포트}`의 형태를 가진다.
: 여러 개의 리스너를 쉼표`,`로 구분해 지정할 수 있다.

> 구버전은 단순한 port 설정을 사용했으나, 지원이 중단되었다.
{: .prompt-info .ms-4 }

**`zookeeper.connect`**
: 주키퍼의 위치를 가리킨다.
: `{호스트이름}:{포트}/{경로}`의 형태를 가진다.
: 세미콜론`;`으로 구분해 지정할 수 있다.


**`log.dir` / `log.dirs`**
: 로그 위치를 가리킨다.
: 카프카는 모든 메시지를 로그 세그먼트 단위로 묶어서 `log.dir` 설정에 지정된 디스크 디렉토리에 저장한다.
: 다수의 디렉토리를 지정할 경우, `log.dirs`를 사용해 지정하면된다.
: `log.dirs`가 지정되어 있지 않은 경우 `log.dir`를 사용한다.
: `log.dirs`에 1개 이상의 경로가 지정된 경우, <question>브로커는 가장 적은 수의 파티션이 저장된 디렉토리에 새 파티션을 저장할 것이다.</question>

> **브로커는 가장 적은 수의 파티션이 저장된 디렉토리에 새 파티션을 저장할 것이다?**
> 만약 현재, 2개의 디렉토리에 파티션이 나눠져 저장되어있다고 가정해보자.
> A 디렉토리에 5개, B 디렉토리에 3개가 저장되어 있다면, 새로운 파티션을 저장할 때 더 적은 파티션을 가지고 있는 B 디렉토리에 저장될 수 있도록 설정한다.
> 이 때, 중요한 점은 **디렉토리의 용량이 아닌 파티션의 개수로 비교한다는 것**이다.
{: .prompt-question .ms-4}

**`nums.recoery.threads.per.data.dir`**~~~~
: 카프카는 스레드 풀을 사용해서 로그 세그먼트를 관리한다.
: 하나의 로그 디렉토리에 대해 하나의 스레드만이 사용된다. 이 스레드들은 브로커가 시작될 때와 종료될 때만 사용되기 때문에 작업을 병렬화하기 위해서는 많은 스레드를 할당하는 것이 좋다.

> **스레드 풀이 하는 일**
> - 브로커가 **정상적으로 시작**되었을 때, 각 파티션의 로그 세그먼트 파일을 연다.
> - 브로커가 **장애 발생 후 재시작**되었을 때, 각 파티션의 로그 세그먼트를 검사하고 잘못된 부분은 삭제한다.
> - 브로커가 **종료**할 때, 로그 세그먼트를 정상적으로 닫는다.
{: .prompt-info .ms-4 }

**`auto.create.topics.enable`**
: 브로커가 토픽을 자동으로 생성하는 몇몇 경우가 있는데, 이는 바람직하지 않은 경우가 많다.<br><question>토픽을 생성하지 않고, 토픽의 존재 여부를 확인할 방법이 없다.</question>
: 이 때, 자동으로 생성할 수 있게 할지에 대한 값이다.

> **자동으로 토픽이 생성되는 경우**
> - 프로듀서가 토픽에 메시지를 쓰기 시작할 때 = **없는 토픽에** 쓰려고 함
> - 컨슈머가 토픽으로부터 메시지를 읽기 시작할 때 = **없는 토픽을** 읽으려고 함
> - 클라이언트가 토픽에 대한 메타데이터를 요청할 때 = **없는 토픽의** 메타데이터를 요청함
{: .prompt-info .ms-4 }

> **토픽을 생성하지 않고, 토픽의 존재 여부를 확인할 방법이 없다?**
> 토픽의 존재 여부를 확인하는 방법
> - `kafka-topics.sh --describe --topic my-topic` 같은 명령어
> - `Kafka AdminClient API (describeTopics()호출)`가 있다.
>
> 설정에 따른 결과
> `auto.create.topics.enable=true`시, 위의 방법으로 확인한다면 **kafka가 토픽을 생성**한다.
> `auto.create.topics.enable=false`시, 위의 방법으로 정확하게 확인할 수 있다.
{: .prompt-question .ms-4 }

**`auto.leader.rebalance.enable`**
: 토픽의 리더가 하나의 브로커에 집중되지 않도록 하는 설정이다.
: 설정을 켜면, 파티션의 분포 상태를 주기적으로 확인하는 백그라운드 스레드가 시작된다.


**`delete.topic.enable`**
: 클러스터의 토픽을 임의로 삭제하지 못하도록 하는 설정이다.

### 토픽별 기본값

**`num.partitions`**
: 새로운 토픽이 생성될 때, 몇 개의 파티션을 갖게되는지 결정한다.
: 자동 토픽 생성 기능이 활성화되어 있을때 사용된다.

> **파티션 수는 어떻게 결정해야하는가**
> 브로커가 추가될 때, 클러스터 전체에 걸쳐 **메시지 부하가 고르게 분산되도록** 파티션 개수를 잡아 주는 게 중요하다.
> <question><b>토픽당 파티션 개수</b>를 <b>클러스터 내 브로커의 수와 맞추거나 배수로 설정</b>하는 경우가 많은데, 
> 이렇게 하면 브로커들 사이에 고르게 분산될 수 있어 메시지 부하 역시 고르게 분산되는 좋은 방법이다.</question>
{: .prompt-info }

> **"토픽당 파티션 개수를 클러스터 내 브로커의 수와 맞추거나 배수로 설정하는 경우"**가 좋은 이유?
> **1. 브로커와 파티션의 관계**
> 각 파티션의 리더는 한 브로커에만 할당된다. 
> - 파티션의 수 < 브로커의 수: 일부 브로커는 파티션을 할당 받지 못해 할 일이 없고, **나머지 브로커만 부하를 받게된다.**
> - 파티션의 수 = 브로커의 수 (* n): 모든 브로커가 파티션의 할당받아 **부하가 비교적 고르게 분산**된다. 
> 
> **2. 브로커 추가 시 유연성 확보**
> 브로커가 추가될 때 **최소 비용**으로 파티션을 재배치(Rebalance)해도 비교적 고르게 분산된다.
> 만약 배수가 아니라면, 비교적 고르게 분산되도록 하기 위한 재배치에는 많은 비용이 들 수 있다.<br> 
> 이 때 유의해야할 점은, **목표가** 완벽한 균등이 아닌 **특정 브로커에만 과부하가 몰리진 않게하는 것**이라는 점과 **리더 파티션을 기준으로 계산**한다는 점이다.
{: .prompt-question }

> [파티션 수를 결정할 떄 고려해야할 요소]
> - **토픽에 대해** 달성하고자 하는 **처리량**은 어느정도인가?<br>
> 100kb vs 1gb
> - **단일 파티션에 대해** 달성하고자 하는 **최대 읽기 처리량**은 어느정도인가?<br>
> 컨슈머의 애플리케이션이 데이터를 DB에 쓰는 속도가 스레드 각각이 초당 50mb 이상을 처리할 수 없다면, 하나의 파티션에서 읽어올 수 있는 속도는 초당 50mb로 제한된다.
> - 만약 키 값을 기준으로 선택된 파티션에서 메시지를 전송하고 있을 경우, 현재의 사용량이 아닌 미래의 **사용량 예측값을 기준으로 처리량을 계산**하라.
> - 각 브로커에 배치할 **파티션 수, 브로커별 사용 가능한 디스크 공간, 네트워크 대역폭** 역시 고려하라.
> - 데이터를 **미러링**할 예정인가?
> 미러링 구성에서 큰 파티션이 병목이 되는 경우가 많다.
> - 클라우드 서비스를 사용하고 있다면, **가상 머신이나 디스크에 초당 입출력(IOPS)제한**이 걸려있는가?<br>
> 파티션 수가 너무 많으면, 병렬 처리로 인해 IOPS 양이 증가할 수 있다.
>
> 경험상 매일 디스크안에 저장되어 있는 파티션의 용량을 6GB미만으로 유지하는 것이 대체로 결과가 좋았다.
{: .prompt-info }

**`default.replication.factor`**
: 새로운 토픽이 생성될 때, 생성되는 토픽의 복제 팩터를 결정한다.
: 자동 토픽 생성 기능이 활성화되어 있을때 사용된다.
: 복제 팩터 값은 `min.insync.replicas` 설정값보다 최소한 1 이상 크게 잡아줄 것을 강력히 권장한다.

**`log.retention.ms`**
: 로그 세그먼트의 시간 기준 보존 주기 설정이다.
: 같은 의미에 단위만 다른 `log.retention.hours`, `log.retention.minutes` 도 설정할 수 있지만, 1개 이상 설정시 가장 작은 단위의 설정값이 우선권을 갖는다.
: 모든 보존 기준은 파티션 단위로 적용된다.

> **시간 기준 보존과 마지막 수정 시각**
> 시간 기준 보존은 디스크에 저장된 각 로그 세크먼트 파일의 마지막 수정 시간(mtime)을 기준으로 작동한다.
> 하지만 관리 툴을 이용해 브로커 간에 파티션을 이동시켰을 경우, 이 값은 정확하지 않으며 해당 파티션이 지나치케 오래 보존되는 결과를 초래할 수 있다.
{: .prompt-info }


**`log.retention.bytes`**
: 로그 세그먼트의 용량 기준 보존 주기 설정이다.
: 모든 보존 기준은 파티션 단위로 적용되기 때문에, 1GB로 설정했고 토픽에 8개의 파티션이 있다면 토픽의 최대 용량은 8GB가 되는 것이다.
: -1로 설정시, 데이터가 영구히 설정된다.


> **크기와 시간을 기준으로 보존 설정하기**
> 만약 시간 기준과 크기 기준 둘 다 설정했다면, AND 가 아닌 OR 과 같이 둘 중 하나의 조건만 성립되어도 삭제될 수 있다.
{: .prompt-info }


**`log.segment.bytes`**
: 로그 세그먼트의 용량 기준 닫힘 주기 설정이다. 
: 로그 세그먼트는 닫히기 전까지는 만료와 삭제의 대상이 되지 않는다.
: 토픽에 메시지가 뜸하게 주어지는 상황이라면, 로그 세그먼트가 의도한 것보다 오래 저장될 수 있다.
ex) 하루 들어오는 양 100MB 이라면 닫히는데 10일이 소요 + 보존 주기 10일 = 최대 20일 보존 


**`log.roll.ms`**
: 로그 세그먼트의 시간 기준 닫힘 주기 설정이다.
: 로그 세그먼트는 닫히기 전까지는 만료와 삭제의 대상이 되지 않는다.
: 같은 의미에 단위만 다른 `log.roll.hours`, `log.roll.minutes` 도 설정할 수 있지만, 1개 이상 설정시 가장 작은 단위의 설정값이 우선권을 갖는다.


> **로그 세그먼트의 시간 기준 닫힘 주기 설정 사용시 디스크 성능**
> 다수의 로그 세그먼트가 동시에 닫힐 때 디스크 성능에 대한 영향을 고려할 필요가 있다. 
> 시간 제한은 브로커가 시작되는 시점부터 계산되기 때문에 크기가 작은 파티션을 닫는 작업 역시 한꺼번에 이루어지기 때문이다.
{: .prompt-info }


**`min.insync.replicas`**
: 브로커가 최소 몇 개의 복제본(Replica)이 최신 상태로 동기화되어 있어야 데이터를 성공으로 간주할지를 결정한다.
: 프로듀서의 <question>acks 설정</question>과 함께 동작한다.

> **acks 설정**
> **프로듀서가** kafka에게 메시지를 보낼 때, kafka가 언제 메시지를 성공으로 간주할지를 결정하는 설정이다.
> - `acks=0`: 프로듀서는 브로커의 응답을 **기다리지 않고** 성공으로 간주한다. 기다리지 않는만큼 빠르지만 데이터가 유실될 위험이 있다.
> - `acks=1`: **리더 브로커만** 메시지를 저장하면 성공으로 처리한다.
> - `acks=all`: 리더와 동기화된 레플리카 **전체가** 데이터를 저장했을 때 성공으로 처리한다.
> 
> **`min.insync.replicas`와 `acks`**
> - `min.insync.replicas`: **브로커**가 성공 응답을 주기 위한 최소 레플리카 수를 정의
> - `acks`: **프로듀서**가 성공을 언제 인정할지 결정
> 
> => `acks=all`설정 없이 `min.insync.replicas`는 의미 없음
{: .prompt-question }

**`message.max.bytes`**
: 쓸 수 있는 메시지의 최대 크기를 제한하는 설정한다.
: 압축된 메시지의 크기를 기준으로 한다.

> 잘못 설정하면 컨슈머가 멈출 수 있다?
> 1개의 메시지 최대 크기인 `message.max.bytes`는 1MB라고 설정되어있고,
> 컨슈머가 한번에 읽을 수 있는 최대 메시지 크기인 `fetch.message.max.bytes`는 512KB 라면
> 브로커는 1MB짜리의 메시지를 반환하려하지만, 컨슈머는 수용할 수 없는 크기라 무시 -> 컨슈머는 다음 오프셋으로 넘어가지 않고 계속 같은 오프셋을 시도하며 무한 대기 상태에 빠짐
> 그렇기 때문에 `message.max.bytes`은 `fetch.message.max.bytes`와 맞추어 설정되어야한다.
{: .prompt-info }

## 하드웨어 선택하기

## 클라우드에서 카프카 사용하기

## 카프카 클러스터 설정하기

## 프로덕션 환경에서의 고려사항

## 요약
